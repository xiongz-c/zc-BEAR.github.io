---
layout: post
title: 初识图论(二)——最短路径、最小生成树、强连通分量
date: 2020-01-04
tag: algorithm
---

期末复习第二篇，总结DSAA的lab题目中出现过的几种算法，可能会在期末考试中出现。这一章做一个简单的梳理(~~写完这个我就可以去做cheatingpaper辣~~)

##### tips：虽然本人用JAVA更熟练，但是考虑到算法题中大多使用C++来实现，并且我也在龟速学习C++，这个标签下的代码都是C++代码。

### 小目录：记录这一章要讲些什么

* 有权图的最短路径算法

> dijkstra 单源有权图求最短路径（只能求无负权）松弛操作的意义

> Floyd-Warshall 解决任意两点间最短路径 （也不可算负权）

> Bellman-Ford 单源最短路（可以判断有无负权）

> SPFA 与上述算法的区别是维护了一个队列，减少了重复操作的次数。 

* 最小生成树/最大生成树
* tarjan

> tarjan应用1：判断是否强连通图（强连通分量是否有且仅只有一个）

> tarjan应用2：配合染色缩点

> 替换方案：两次DFS，适用于考试下——防止tarjan不给分/需要写出DFS过程的题目

### 图进阶：基本的图相关算法学习

在第二次的图作业中，我们主要涉及到了三个算法：dijkstra、最小生成树、tarjan。

### 单源有权图(无负权)求最短路径

图论中很经典的问题就是求两个点之间的最短路径，针对已知出发点的问题，可以通过dijkstra算法求得图中的所有点距离该点的最短路径。dijkstra算法其实就是一个很简单的松弛操作：遍历优先队列的点，在每个点里遍历连向的NEXT向量，对每一个NEXT的点，利用“三角形三边关系”比较一下长短，更新路径长度，不断重复此过程直到遍历完全图。写成代码的形式大概是如下的样子：
```cpp
    dist[u] = 0;
    priority_queue<Node> q;
    q.push(Node{u,0});
    while (!q.empty())
    {
        now = q.top().index;q.pop();
       if(done[now])continue;
        done[now] = true;
        for(Node e : from[now])
        {
            int nxt = e.index;
            if(dist[nxt] > dist[now] + e.val)
            {
                dist[nxt] = dist[now] + e.val;
                q.push(Node{nxt,dist[nxt]});
            }9
        }
    }
```
以上是dijkstra的核心代码，不过在我们的作业题中还有一题([Lab9_E Portal](https://acm.sustech.edu.cn/onlinejudge/problem.php?cid=1061&pid=4))涉及到了分层图，面对分层图问题时我们可以考虑建立k倍大小的图进行dijkstra，这个题目也有可能在期末考试中出现，以下附上这题的源码：
```cpp
//省略一些头文件、常量及快读板子
struct Node{
    int index;
    ll val = INF;
    Node(int index,ll val){
        this->index = index;
        this->val = val;
    }
 
    bool operator < (const Node &x)const{
            return x.val < val;
    }
};
int n,m,p,k,u,v,now;
ll w;
bool done[MAXN*10];
ll dist[MAXN*10];
vector<Node> from[MAXN*11];
int main(){
    n = read();m = read();p = read();k = read();
    for (int i = 1; i < m+1;++i)
    {
        u = read();v = read();w = read();
        for (int j = 0; j <= k; ++j)
        {
            from[u+ n*j].emplace_back(v + n*j,w);
        }
    }
    for (int i = 0; i < p; ++i)
    {
        u = read();v = read();
        for (int j = 0; j < k; ++j)
        {
            from[u+ n*j].emplace_back(v + n*(j+1),0);
        }
    }
    u = read(),v = read();
    for (int i = 1; i <= n*10 ; ++i) {
        dist[i] = INF;
    }
    dist[u] = 0;
    priority_queue<Node> q;
    q.push(Node{u,0});
    while (!q.empty())
    {
        now = q.top().index;q.pop();
       if(done[now])continue;
        done[now] = true;
        for(Node e : from[now])
        {
            int nxt = e.index;
            if(dist[nxt] > dist[now] + e.val)
            {
                dist[nxt] = dist[now] + e.val;
                q.push(Node{nxt,dist[nxt]});
            }
        }
    }
    ll minLen = INF;
    for (int  j = 0 ; j<=k;  j++) {
        minLen = min(minLen,dist[v+j*n]);
    }
    printf("%lld",minLen);
    return 0;
}
```
理解了思路dijkstra也就是五六行的事情，比较新颖的是分层图的做法，了解了分层图整个代码之后dijkstra可以说基本掌握了，下一部分是与此相似的最小生成树算法。

### 最小/最大生成树

虽然标题是最小/最大生成树，但是其实这个部分的算法只有最小生成树，用脚趾头想想也知道，最大生成树其实只是最小生成树改一个比较条件而已。求出一个图中的最小生成树的两个基本算法是Kruskal和Prim算法。前者因为复杂度的分析比较复杂，我们仅作了解即可，后者是我们在课堂上教的方法，需要实现并分析其复杂度。这一部分主要讲Prim算法的一些细节。

根据算法导论上面的描述，Prim算法的思路是这样的：

> 随意选择一个起点，把这个根节点加进集合A中，算法的每一步在连接集合A和A之外的节点的所有边中，选择一条轻量级边加入到A中，这样每一次加入的都是一条安全边，保证了A中的边形成一棵最小生成树。本策略也属于**贪心策略**。

这样的描述比较直观，如果转化成伪代码的形式就是下面这样的(来自算法导论第三版)

>MST-PRIM(G,w,r)

> for each u $\in$ G.V

>    u:key = $\infty$

>    u:$\pi$ = $NIL$

> r:key=0

> Q = G.V

> while Q $\neq$ $\varnothing$

>    u = EXTRACT-MIN(Q)

>    for each v $\in$ G.Adj[u]

>    if v $\in$ Q and w(u,v) < v.key

>    v.$\pi$ = u

>    v.key = w(u,v)

**一个给自己的小提醒：在这次作业题中我写的prim算法有点小问题，但还是过了OJ，希望看到这条提醒的自己重新去写一下prim，写完了这条提醒就删掉**

以上就是Prim算法的写法，需要记住Prim算法的时间复杂度是O(VlgV + ElgV) = O(ElgV)，从渐进意义上来说与Kruskal算法的运行时间相同。(如果使用斐波那契堆来实现最小优先队列Q可以使运行时间进一步缩短到O(E + VlgV)，详情可以查阅算法导论上斐波那契堆部分的解释)

还有一个小知识点：老师上课讲得prim和算法导论上的也有一点点小区别：

* 课上的比较简单，每次遍历到一个点就把相关的边加进小根堆中，通过不断的插入操作使得最小的边可以浮动到堆顶，每次加入最小的边；

* 算法导论上面的prim是先把图中的所有点加进二叉堆中，再一个个删掉点。这样做的难度是要自己实现一下删点时二叉堆的浮动，但好处是二叉堆此时最多只有n(节点数)而不是至多$n^2$(边数)的元素，在取出元素时的时间会更少一些。不过也只是常数级别的影响而已，写第一种写法其实也挺轻松愉快的，这里只是稍微提一下。

### Tarjan算法：求强连通分量

Tarjan是本学期学到的最后一个有名字的算法了，这个算法应用于求一个图的强连通分量，同时也可以用于判断强连通图等宇强连通分量有关的问题。同样的，这个算法能解决的问题我们也可以用更普通的算法——两次DFS解决，同时这也是我们上课唯一指定解决方案，这会在讲完Tarjan后提到。而Tarjan在解决这些问题上的优势在于只需要遍历一遍(是的，也只是一个常数级别的优化而已)。考试中用Tarjan应该是没有问题的，当然两遍DFS的方法也要掌握，如果时间充裕的话可以用两遍DFS更为保险。

既然是讲到一个求连通分量的算法，那我们肯要定从回顾强连通分量的一些相关概念开始。

#### 强连通图，强连通分量和强连通子图的区别？

**连通**

首先是连通这个概念，顾名思义，连通就是两个点不是孤立的——至少有一条路径可以把两个点相连，需要注意的是这里的路径并不一定是**直达**的，只要有路可以去就行了。

**强连通**

强连通的定义是：对于两个点A和B，既有路线从A到B，也有路线从B到A，则称A与B是强连通的。

**强连通图**

依据强连通的概念，强连通图就是图中的任意两个点都相互有路径抵达。从强连通的定义出发我们可以很容易得到一个推论：对于一个无向图来说，连通图一定是强连通图。

**强连通子图和强连通分量**

这两个概念从名字上有点难区分，都是指一些点之间互相都是强连通的。但是从定义上来说他们还是有不小的区别

* 强连通子图：就是一些强连通的点的集合，可以理解为强连通图的子集，这个子集可以是任意的，只要满足强连通图的概念即可。

* 强连通分量：这个概念就要比强连通子图要严格一些，强连通分量指的是在一个图中**极大的**强连通子图。即一个强连通分量是这些点可以构成的最大的强连通图。一个图中可以有多个强连通分量，但这些强连通分量肯定是彼此分开的。同样地，我们可以得到两个推论：

    1.一个孤立的点是一个强连通分量。

    2.一个图是强连通图的充要条件是它有且仅有一个强连通分量。

#### Tarjan介绍

这里总结tarjan是以Lab的题目为基础的，可能不是太全面，如果读者认为这一部分有讲的不太清楚或者有遗漏的地方，可以参考[OIwiki——强连通分量部分](https://oi-wiki.org/graph/scc/)的讲解，上面对这个算法讲得比较清晰。

好，现在让我们回到我们的复习，Tarjan算法的作用在前面已经提到过，适用于找到一个图中的强连通分量。为了减少查询的次数，Tarjan算法在遍历每一个点都维护了两个变量: dfn[v] 和 low[v]。这两个数组的作用如下：

>dfn[v]：用于记录节点v被搜索到的次序，每次搜索到某个v时该节点的dfn就+1

>low[v]：对于一个以节点v为根节点的子树，low[v]定义为这个树上节点的dfn的最小值——即dfn每次搜索递增，但low在每个树内部不会增加

这样操作的好处是在遍历的过程中就可以做一个是否回到根节点的判断。在每次搜索的过程中，Tarjan算法会持续做判断，对未访问过的点进行深度优先搜索，对访问过的点且在栈中的更新low值，对访问过的且已经出栈了的是不会进入Tarjan的。最后在递归尾部判断这个节点是否是根节点，若是根节点就进行相应的出栈划分强连通分量的操作。

这里放出DSAA作业里[Lab9_F题](https://acm.sustech.edu.cn/onlinejudge/problem.php?cid=1061&pid=5)里面写过的Tarjan算法。

```cpp
void tarjan(int x)
{
    DONE[x] = LOW[x] = cnt++;
    s.push(x);
    inStack[x] = 1;
    for(int ii : tail[x])
    {
        if(!DONE[ii])
        {
            tarjan(ii);
            LOW[x] = LOW[x] < LOW[ii] ? LOW[x] : LOW[ii];
        }
        else if(inStack[ii])
        {
            LOW[x] = LOW[x] < DONE[ii] ? LOW[x] : DONE[ii];
        }
    }
    if(LOW[x] == DONE[x])
    {
        colindex++;
        minIndex = s.top(),minTime = nodes[s.top()].t;
        while (!s.empty())
        {
            num = s.top();
            col[num] = colindex;
            s.pop();
            inStack[num] = 0;
            if(nodes[num].t < minTime)
            {
                minIndex = num;
                minTime = nodes[num].t;
            }
            if(num==x)break;
        }
        G.push_back(minIndex);
    }
}
```

这里面最后的判断记录了一下每个强连通分量相对应的根节点，还做了一个染色的操作，如果只需要大小的话记录一个size就可以了，有其他的操作需求可以做相应的改写。需要记住的是，Tarjan的算法复杂度是O(m+n)。

#### 关于染色缩点

在讲强连通分量的时候，就不免会提及到与染色有关的问题，就像上一部分的题目一样，找强连通分量的一个目的就是把他们结合成**一个整体**。不过只要做过一遍题目就能很容易理解，只需要开一个数组做一个染色操作就可以给这些点赋予一个变量记录他们的**共性**，从而达成染色缩点的目的。这道题目中有一个合并入度的操作就可以在染色之后完成，效率还是很高的。详细的操作就不罗列了，不是太需要关注的地方。

#### 两遍DFS

Tarjan算法十分地优雅了，但是更好理解的DFS还是需要了解一下的，考场上可以用这个方法确保改卷老师不会扣你分。这个算法也叫Kosaraju算法，只需要进行两遍DFS就能找到强连通分量。(以下内容全部来自oi-wiki)

>第一次 DFS，选取任意顶点作为起点，遍历所有未访问过的顶点，并在回溯之前给顶点编号，也就是后序遍历。

>第二次 DFS，对于反向后的图，以标号最大的顶点作为起点开始 DFS。这样遍历到的顶点集合就是一个强连通分量。对于所有未访问过的结点，选取标号最大的，重复上述过程。

>两次 DFS 结束后，强连通分量就找出来了，Kosaraju 算法的时间复杂度为 O(n+m)。

实现的代码十分简单，也比Tarjan好理解
```cpp
void dfs1(int u) {
  vis[u] = true;
  for (int v : g[u])
    if (!vis[v]) dfs1(v);
  s.push_back(u);
}

void dfs2(int u) {
  color[u] = sccCnt;
  for (int v : g2[u])
    if (!color[v]) dfs2(v);
}

void kosaraju() {
  sccCnt = 0;
  for (int i = 1; i <= n; ++i)
    if (!vis[i]) dfs1(i);
  for (int i = n; i >= 1; --i)
    if (!color[s[i]]) {
      ++sccCnt;
      dfs2(s[i])
    }
}
```
### 图论基础部分完结

不知道是因为最后的课程讲得匆忙还是出题的某人比较善良，最后一次Lab的题目并没有很为难大家，基本上掌握了这三个算法就能轻松过掉了。可以说DSAA的复习部分就到此为止了，但是作为程序员必须掌握的一些基础的算法甚至还没有讲完。基础部分的算法估计还有红黑树等一些树的部分和图里面几个没有讲到的算法，这些部分的内容可能会在寒假抽空补齐。废话就这么多，剩下的几天里期末考试加油吧！