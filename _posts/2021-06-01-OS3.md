---
layout: post
title: 操作系统复习（三） Storage、IO与File System
date: 2021-06-01
tag: SUSTech
---

## Lecture 8 Address Translation

#### 程序准备运行的几个步骤

1. compile time编译期
2. link time 链接期
3. load time 加载期
4. execution time 运行期（动态链接库）

#### 多种内存访问方式

* Uniprogramming

  系统中只有一个进程运行，可以访问所有的物理空间，不存在冲突也没有保护和地址转换

* Multiprogramming

  系统中有多个程序同时运行，如果不加保护一个进程会影响另一个进程运行。如果一个进程有问题会导致另一个进程crash。这个时候最基本的想法是使用BaseAddr和LimmitAddr保持地址不互相冲突，用户态不能改变这两个寄存器的值。

* Virtual Memory

  * MMU：memory management unit

  ![MMU](/images/posts/os-review/mmu.png)

  * Base & Bounds method

    会产生内存碎片，一个大的frame没法拆开插进两个小的间隙

  ![B&B](/images/posts/os-review/baseAndbound.png)

  * Multi-Segment Model



## Lecture 9 Caching

**Cache: a repository for copies that can be accessed more quickly than the original**

Average Access Time = Hit Rate x Hit Time + Miss Rate x Miss Time

#### 三种缓存映射方式

* direct mapped cache：对内存的映射是均匀的，而内存的访问不是对每个地址均匀的，会导致非热点数据地址闲置率比较高，造成cache空间浪费

* set associative cache：把cache分成多个等长的set，相当于对每个set做fully associative，这样就降低了遍历的复杂度。对于一个32位的系统来说，具体的划分是：最低的4位是偏移量，中间的4位是组号，最高的24位是唯一对应的tag。所以一个地址可以唯一确定一个cache set， 再遍历set找到位置。这里有一个小细节：**set段是从低位开始的**， 这样做是因为在内存的访问中经常是连续的，而连续的地址空间高位是相同的，如果用地址高位作为set段会导致L2L3有着很高的miss率，影响程序整体的执行效率。

* fully associative cache：Every block can hold any line，每次比较需要遍历整个cache，效率很低

#### Demand Paging 按需分页

程序运行时90%的时间都在运行10%的代码，所以并不总是需要所申请的那么多内存。大部分的内存会存储在磁盘上，只有需要时才会调出来到物理内存上使用。

Effect Access Time = Hit Rate x Hit Time + Miss Rate x Miss Prnalty

#### Page Replacement Policies

* FIFO (First In, First Out) 最易实现
* MIN (Minimum) 理论最优，无法实现
* RANDOM 随机访问
* LRU (Least Recently Used) 双向链表+map
* Clock 环形链表

## Lecture 10 I/O & Storage

### I/O 计算机与外部设备的通信

#### 几种形式的对比：

* Byte v.s. Block：键盘的输入关注单个信号，但磁盘的输入考虑整块
* Sequential v.s. Random：打字对顺序要求高，但拷贝行为可以顺序随机

#### Kernel Device Structure

![structure](/images/posts/os-review/kernel-device-structure.png)

#### Example: PCI Architecture

![structure](/images/posts/os-review/pci-arch.png)

#### Transferring Data To/From Controller

##### Programmed I/O

* Each byte transferred via processor in/out or load/store 
* Pro: Simple hardware, easy to program
* Con: Consumes processor cycles proportional to data size

##### Direct Memory Access

- Give controller access to memory bus
- 3  Ask it to transfer data blocks to/from memory directly

#### I/O Device Notifying the OS

##### I/O Interrupt 告知os发生了错误

* Device generates an interrupt whenever it needs service 3 Pro: handles unpredictable events well
* Con: interrupts relatively high overhead

##### Polling 告知os完成了任务

* OS periodically checks a device-specific status register ® I/O device puts completion information in status register
* Pro: low overhead

- Con: may waste many cycles on polling if infrequent or unpredictable I/O operations

#### Life Cycle of An I/O Request

![life cycle](/images/posts/os-review/io-lifecycle.png)

#### Basic Performance Concepts

* Response time or latency
* Bandwidth or throughput
* start up or "overlhead"

### storage

HDD/SSD的一些区分

性能的衡量指标：IO表现

* EffBW(n)=n/(S+n/B)=B/(1+SB/n)

#### Disk Scheduling 几种磁盘寻道算法

* FIFO 先来先服务，按顺序直接访问
* SSTF 最短寻道时间优先，每次访问的下一个节点是离当前节点最近的
* SCAN 从某个方向（自定义，一般往数字小的）访问到0，再回头访问到另一头
* C-SCAN 访问到一个方向尽头，再从0开始往同一个方向访问到结束
* LOOK 不访问到0点SCAN
* C-LOOK 不访问到0的C-SCAN

SSTF对频繁的读写性能较好，因为这些操作往往位置上比较接近。

LOOK/SCAN对大容量的读写性能较好，即在连续的空间上不容易发生饥饿。

## Lecture 11 File System

##### **Directory**：Basically a hierarchical structure

* Each directory entry is a collection of 
  * Files
  * Directories
    * A link to another entries
* Each has a name and attributes
  * Files have data
* Links (hard links) make it a DAG, not just a tree
  * Softlinks (aliases) are another name for an entry

##### **File**： Named permanent storage

* Data
  * Blocks on disk somewhere
* Metadata (Attributes)
  * Owner, size, last opened, ... 
  * Access rights
    * R, W, X
    * Owner, Group, Other (in Unix systems)
    * Access control list in Windows system

#### File System

##### contiguous allocation

连续分配，每个文件分配一组位置相连接的盘块（连续的物理地址），每个文件都连续存放。问题是删除文件后就容易出现碎片的问题（除非及时移动文件，但是这样做消耗很大），老式的磁盘光盘等会用这样的形式存储文件（因为一般不会有删除操作，能保证完整性）

##### linked allocation

链接分配，把文件打散存储，每个盘块中存储文件的一个逻辑页。通过在盘块上设置一个指针将同一个文件的盘块顺序地连接在一起，链接顺序和文件逻辑顺序保持一致。

* 显示连接：每个文件的第一个盘块的编号放在文件目录中，其他放在FAT中
* 目录和FAT一起记录哪些盘块分给了文件以及其逻辑顺序

##### inode allocation

对每个文件建立一张索引表，记录其分配给该文件的物理盘块，以及相应的逻辑顺序对应关系。

* 单级索引：每个文件一张索引表，这张索引表放一个盘块
* 多级索引：对于一个盘块放不下的大索引表，可以拆成多个，然后对着多个索引表再建一张索引表
* 混合索引：混合使用多种索引方式

#### File Allocation Table（FAT）文件分配表

每个盘块中存储文件逻辑的块就是FAT。后面的数字表示可以存储几个bit的数据(注意FAT32只能到2^28)。

##### 如何计算一个 File System Size？

e.g.已知 block size = 32 KB， block address=28 bits

​		**Size = 32 x 2^10 x2^28 = 2^43(8TB)**

##### FAT series — layout overview

![layout](/images/posts/os-review/fat-layout.png)

##### FAT series — normal & LFN directory entry

![directory entry](/images/posts/os-review/fat-dir-entry.png)

##### FAT series — File

* Read：从每个块往下一个cluster跳，跳到EOF说明读完了
* Write：往空的cluster写，通过FSINFO申请下一个cluster，写入后更新FATs和FSINFO，全部写完后更新file size。
* delete：并不是把所有数据都删除了，只是把索引删除了

