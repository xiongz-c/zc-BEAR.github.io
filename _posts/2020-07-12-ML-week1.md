---
layout: post
title: 机器学习-Week1笔记
date: 2020-07-12
tag: ML-notes
---

### 写在前面的话

从这个星期到暑假结束，我们的任务都是对着[bilibili上李宏毅老师的机器学习课程](https://www.bilibili.com/video/BV1JE411g7XF?from=search&seid=14695487908495095953)进行学习。因为这个课程对我来说有一定难度，将来一定需要反复翻看课程笔记资料，因此这里开启ML-notes标签，记录这段时间的学习笔记。因为每个专题的长度相差还蛮大的，分开许多零碎的小节也不方便翻看（~~懒得一篇篇整理~~），就以周为单位，每周更新一篇博客作为当周的学习笔记。

## Regression: Case Study 回归——样例分析

> 案例：宝可梦cp值分析，根据已有的宝可梦进化前数据，预测宝可梦进化后cp值大小
>
> 确定三个要素：
>
> * Senario：根据data决定，input是进化前的宝可梦，output是进化后的cp值。因此data是labeled，使用的Senario是**Supervised Learning**
> * Task：根据function的输出类型决定Task，因为需要一个scalar，因此使用的task是**Regression**
> * Model：本样例采用**Non-linear Model**

### Regression的具体过程

#### 回顾一下machine Learning的三个步骤：

- 定义一个model即function set
- 定义一个goodness of function损失函数去评估该function的好坏
- 找一个最好的function

##### Step 1： Model

Model的确定只能根据经验判断和尝试

使用Linear Model：$y = b+\sum \omega_i x_i$ 

##### Step 2： Goodness of Function

定义两个参数：

$x^i_j$： 用上标来表示一个完整的object的编号，下标表示第j个参数

$\hat{y}^i$：表示第i个object实际观测到的输出，是一个数值

**Loss function**

使用损失函数评估模型的好坏：$L(f)=L(\omega,b)$

与模型的选择标准相同，Loss function的选择也是根据经验来决定，常用的形式是方差和：

$L(\omega,b)=\sum^{10}_{n=1}(\hat{y}^n-(b+\omega\cdot x^n_{cp}))^2$

损失函数的值越小，说明我们的function的loss比较小，模型表现较好

##### Step 3： Pick the best function

找到Loss Function的global optimal。

### Gradient Descent

只要$L(f)$可微分，就可以使用这个方法处理$f$，找到表现较好的参数。

1. 选取一个适当的店$\omega_0$，计算该点函数的微分
2. 若微分小于0则向右走，反之向左走
3. 步长取决于两件事
   1. 微分的值，越大移动距离越大
   2. 一个常数$\eta$, Learning rate。由使用者设置的学习速率，越大学习速度越快，但是太大了有可能会跳过合适的global optimal。



**回到本问题：两个参数的问题**

本质上是一样的，只是对两个参数分别做微分，直到两个参数都到极小值点。从图像上解释就是每次得到的向量，即数学上的梯度，都是向着等高线的法线方向的。

**Gradient Descent的缺点**

* 遇到很平缓的函数时速度很慢

* 遇到坑坑洼洼（多个极值点）的函数可能会找到local minima
  * 在Linear Regression上，函数是convex的，即只有一个极小值，不会有local minima

### 回到宝可梦的问题

#### 考虑不同model的影响

通过尝试不同的model会发现次数越高对training data的拟合度越好，但是复杂到一定程度以后对test data就会错误率暴增，这种现象称为**过拟合**。本例种，三次方的模型是最适合的model

#### 考虑其他参数的影响

本例中的其他参数包括物种/HP值/Height值/Weight值等等，这些参数也有可能对模型产生影响。但是和上面一样，越多的模型参数越有可能导致overfitting的情况。因为有的参数可能并不是真正的影响因素，而却在训练的时候考虑进去了。

### Regularization 解决overfitting

**L2正则化：**在原有的$L(f)$基础上加上一个$\lambda\sum(\omega_i)^2$， 可以综合考虑参数和训练集误差。通过手动调整$\lambda$可以调整比重。

知识补充：

>L1正则化：取$\omega$的绝对值求和，用于产生稀疏模型
>
>L2正则化：取$\omega$的平方求和，防止过拟合

## Gradient Descent专题

上一节的介绍是大致的方法，这一节会说更多的相关技巧

### Learning Rate的问题

**不同的速率可能会引起不同的结果（红色是适当的速率）**

![img](/images/posts/ML-notes/learning-rate.png)

#### 朴素Gradient Descent

* **vanilla gradient descent**
* **Gradient Descent with Momentum**
* **Nesterov Accelerated Gradient（NAG）**

但是基础的算法是以以相同的学习率去更新$\theta$的各个分量。而深度学习模型中往往涉及大量的参数，不同参数的更新频率往往有所区别。对于更新不频繁的参数，我们更希望单次步长更大，多学习一些知识；对于更新频繁的参数，我们则希望步长较小，使得学习到的参数更稳定，不至于被单个样本影响太多。因此需要Adaptive的算法。

 #### Adaptive Learning Rates

Learning Rates不一定要是常数，可以是一个适应性的公式，比如说是一个随着不近次数改变的公式 E.g. $\eta^t=\eta\sqrt{t+1}$ .

**最基本、最简单的大原则是：learning rate通常是随着参数的update越来越小的**

* **ADAGRAD：** 
  * $\frac{\eta}{\sqrt{\sum^t_{i=0}(g^i)^2}}g^t$ 
  * 分母存在的意义：虽然在单参数的function里我们认为一次微分的大小与到最低点的距离成正比，但是**gradient越大，离最低点越远这件事情在有多个参数的情况下是不一定成立的**。因此我们需要估算二次微分的大小，而这个公式的分母就是在不额外增加运算的前提下尽可能估测二次微分的大小。

* **ADAM：**
  * 可以认为是 **RMSprop** 和 **Momentum** 的结合。和 RMSprop 对二阶动量使用指数移动平均类似，Adam 中对一阶动量也是用指数移动平均计算。
  * 具体做法略（这个课没有讲）
* **Stochastic Gradient Descent（SGD）：**
  * $L^n=(\hat{y}^n-(b+\sum w_ix^n_i))^2$
  * $\eta \triangledown L^n(\theta^{i-1})$ 
  * 不同于传统的梯度下降思路——看完所有的样本点后构建损失函数然后去update参数，而是在单独的样本点求出error的平方和，即每次下降的值的一部分是随机样本点的error的平方和。

### Fearure Scaling

特征缩放，如果不同的特征（参数）分布范围显著不一样时，把他们缩放到一个范围内。如果一个loss function在w1，w2平面上的投影是一个正圆形，会比较容易update参数。否则必须使用多learning rate的梯度下降方法。所以feature scaling有助于提高参数update效率。

#### 如何做Feature Scaling

其实就是归一化成标准正态分布

* 对每个维度$i$，算出平均值$m_i$ ，标准差$\sigma_i$
* 对第r个参数，$x^r_i=\frac{x^r_i-m_i}{\sigma_i}$
* 就得到了一个标准正态分布$f(x_i)=\frac{1}{\sqrt{2\pi}}e^{-\frac{x^2_i}{2}}$

### Gradient Descent 的理论基础

#### 数学基础——Taylor Series

* 一般只使用一阶的展开，往后计算量会很大，降低运行效率
* 理论上learning rate 无穷小才能保证每次update的loss一定降低，符合泰勒近似
* 具体推导的公式好长，不想写了，下图就是大致的思路：![img](/images/posts/ML-notes/taylor.png)

### Gradient Descent 的限制

**在gradient即微分值接近于0的地方就会停下来，而这个地方不一定是global minima**

* 可能是local minima
* 可能是saddle point（鞍点）
* 可能是一个很平缓（斜率很接近0）的高原

## Classification  机器学习另一重要问题——分类

在分类问题中，function的输入需要数值化

### How to classification

#### 可以当成Regression问题来解吗？

**本质区别：Regression的output是连续性质的数值，而classification要求的output是离散性质的点**

如果想要把接近某个数值的点都归为同一类从结果上看是似乎是对的，但是这样的思路是反过来思考问题。因为对于一个分类问题，输入的点都是离散地几种在某些点上，这样的数据进行Regression得到的结果是不好的。**而且很多时候分类之间是没有直接联系的**，不同的分类没有数值上的可比较性，这样的标签用Regression也是无法得到好的结果。

#### 一些模型的转换

**Function（Model）**

不同于Regression，分类器中function的输出是离散值

**Loss Function**

$L(f)=\sum\parallel (f(x^n)\neq \hat{y}^n)$，使用这样形式的Loss Funcion即分类错误造成的影响是固定的，因为分类问题中，没有离正确答案离A类比B类更近这种说法。

因为是离散的值，这个Loss Function无法微分，所以 **Gradient Descent** 的方法就不适用于解决分类问题了

#### Generative Model

利用贝叶斯公式，考虑一个二分类问题

![img](/images/posts/ML-notes/two-class.png)

要算$P(x\mid C_1)orP(x\mid C_2)$，就需要得到另外三个值，但这个值我们显然是不知道的，所以要用已知的数据训练得到这三个值的近似值。

*这一整套想法叫做**Generative model**(生成模型)，为什么叫它Generative model呢？因为有这个model的话，就可以拿它来generate生成x(如果你可以计算出每一个x出现的概率，就可以用这个distribution分布来生成x、sample x出来)*

##### Prior

$P(C_1)和P(C_2)$这两个概率，被称为Prior。

直接从训练集中得到就好了，比较简单，困难在于如何获取另外两个参数。

##### Probability from class

$P(x\mid C_1)orP(x\mid C_2)$是比较难以计算的值。因为在一些有着全新特征的物种出现之前，training data中是不存在这个数据的，可能性会是0，但是显然不能用0来建模，因为在总体的数据上这个概率肯定大于零。这里就需要高斯分布的知识了。

##### Gaussian Distribution

![img](/images/posts/ML-notes/gaussian-distribution.png)

* 同样的$\Sigma$,不同的$\mu$， 概率分布的最高点是不一样的
* 同样的$\mu$,不同的$\Sigma$， 概率分布的最高点一样，但分布的密集程度是不一样的

##### 求Gaussian Distribution的方法

使用**Maximum Likelihood极大似然估计**计算出两个参数的值

可以分别计算出class1和class2的两个参数【得到两个高斯分布】，就可以计算出$P(C_1\mid x)$或$P(C_2\mid x)$关于x的一个表达式，这个市后只需要代入input x就可以判断属于class1和class2的概率了。如果我们按照概率>0.5来分的话，会发现这个分类器的准确度很低，只有47%。

##### 维度不足导致的效果不佳

这里只使用了两个dimension的参数，但是之前提到一个宝可梦是有六个dimension的特性参数的。所以也许在二维空间上会有很多的点重叠，但是在六维的空间上会区分的比较开。这里使用六维的计算时准确率为54%，有所提升，但还是很糟糕。

#### Modifying Model

![img](/images/posts/ML-notes/modify-model.png)

其实大多数情况下不会给每一个class都有不同的参数。

比较常见的做法是，**不同的class可以share同一个cocovariance matrix**。

因为feature的数量很大的时候，容易出现overfitting的情况

##### 共用后的结果

共用了covariance matrix之后两个class的分界线会变成一条直线。

实验证明对于课堂的案例我们考虑所有的feature，并共用covariance的话，原来的54%的正确率就会变成73%。

### Three Step

分类问题中一样是三个步骤，这里回顾一下：

* Function Set（Model）：
  * 模型其实就是一个贝叶斯公式
* Goodness of a function
  * 找参数为什么用高斯分布：因为常用，具体选择什么要依靠经验决定
  * 比如一个特性是binary的，就不要选择高斯分布了，伯努利分布可能更适合
* Find the Best function：easy

### Posterior Probability

分析一下这个概率公式：

![img](/images/posts/ML-notes/posterior-probability.png)

把Z推导一下（过程就不写了，记一下结论）

![img](/images/posts/ML-notes/z-final.png)

从最后的结果可以解释，为什么公用$\Sigma$的时候，他们之间的boundary回事linear的。

这里抛出一个疑问：

从最终的式子可以看出，我们的最终目标不就是找一个向量$\omega$和一个常量b吗，为什么要搞那么多来算$\mu$和$\Sigma$呢，有没有办法**直接把向量$\omega$和常量b找出来**呢？这是下一章【下周】要讲解的内容！
