---
layout: post
title: 机器学习-Week3笔记
date: 2020-07-26
tag: ML-notes
---

## Recurrent Neural Network(RNN)

像分类问题这样的问题，上一个用来分类的物品和下一个没什么关系。但是像NLP这样的问题，后面的词性和上下文其实是有关系的，所以这个时候我们就需要neural network需要有记忆，也就是【循环神经网络】。

### RNN的结构

相比于常规的神经网络，这里在hidden layer里面加了一个存储的结构，存储上一次的hidden layer的值（或者上几次），输入的时候其实就是存储的值和新的输入一起输入进行学习。

#### 两种不同的RNN网络 Elman NetWork & Jordan NetWork

![image-20200723110319476](/images/posts/ML-notes/image-20200723110319476.png)

#### Bidirectional RNN

RNN不仅可以是单向的，也可以是双向的，可以train一个正向的network，也同时是train一个逆向的network。整个input sequence的值都可以被双向的RNN看到，从而得出更好的训练结果。

![image-20200723110607145](/images/posts/ML-notes/image-20200723110607145.png)

#### The Problem of Long-Term Dependencies

在某些情况下可能某些词只跟前面几个单词有关，但是还有些情况下某些词会和很长的句子前面的词有关，RNN就无法处理这样的问题。

因为序列后面的梯度很难反向传播到前面，就会产生梯度消失的问题

### Long Short-term Memory（LSTM ）

#### Three gates

对于一个neural来说，会有四个input/一个output/三个gates

* Input gate：决定其他neural的值是否需要输入这个neural
* Forget gate：决定什么时候把memory的东西forget
* Output gate：决定其他neural可不可以把这个neural的值取出来

![image-20200723113315107](/images/posts/ML-notes/image-20200723113315107.png)

#### Formula

对于上面这个图的三个门，都有具体的公式进行描述。

下图中的activation function f为sigmoid function，黑色圆点表示multiply；$z_i,z_o,z_f$分别操控input、output、forget gate；$z$表示外界要存入的值.

如果$f(z_f)$的输出值为1，表示打开forget gate（memory）；输出值为0，表示关闭forget gate（forget）

对于输入的$z$值，经过activation function $g$运算后为$g(z)$，相应的$z_i$经过运算得$f(zi)$，c为Memory的初始值，当forget gate开启的时候，$c’$表示经过一次forget gate打开时进行计算后更新的值.

![image-20200723114219924](/images/posts/ML-notes/image-20200723114219924.png)

memory cell的输出再输入activation function h，输出$h(c')$，即可得出该neural的output为a
$$
a=h(c')f(z_0)
$$
*这里偷一点懒，具体的实现看的不是很明白，就先不记录了，以后看明白了再补充*

#### Original Network V.s. LSTM

首先是参数的区别

* 一般的neural network只需要操控$(x_1,x_2)$只有一组参数
* LSTM需要将$(x_1,x_2)$乘以不同的weight作为四个不同的输入，参数相当于是四倍的数量

#### RNN V.s. LSTM

* 依赖程度不同
  * 传统RNN直接在每一次迭代覆盖输入，只能处理短期依赖
  * LSTM采用类似于累加的形式，可以处理长期依赖
* 参数更新公式不同
  * RNN: $h_t=tanh(W_h\cdot[h_{t-1,}x_t]+b_h)$
  * LSTM: $c'=g(z)f(z_i)+cf(z_f)$, $a=g(c')f(z_0)$

### Learning

RNN的训练也是前向和逆向传播都有，所以也需要用到逆向传播的公式Backpropagation through time（BPTT）

但是基于RNN的network不是很容易训练，因为他的error surface要么非常steep要么非常flat。很容易一不小心loss就太大了或者根本走不动。

![image-20200723121057570](/images/posts/ML-notes/image-20200723121057570.png)

#### Clipping

当gradient大于15的时候，就看做是15，不再继续增加，这时gradient的移动方向就是图中的蓝色虚线部分，就不会再飞出去了，仍然可以继续做RNN training。

#### Why we have this problem

直接给结论：RNN不好训练的原因并不是因为activation function的影响，而是**由于weight在high frequency地被使用**，weight在不同的位置、不同的时间点是会被反复地使用的。

#### Helpful Techniques

**LSTM**可以让error surface不那么崎岖，可以把一些很平坦的地方拿掉，使error surface不再有那么平坦的地方；**可以解决gradient vanishing问题，但并不能解决gradient exploding的问题**，有的地方还是会特别崎岖，因此在使用LSTM时，需要设置很小的learning rate。

##### LSTM可以解决gradient vanishing的原因：

* 因为LSTM当前的input和memory里的值是“相加”的，每次都会有新的东西加进来；但RNN却是相乘的，只要weight有一点小小的变化，其output都会产生巨大的变化，**如果相加就不会有这么大的变化 。**
* 如果forget gate是打开的状态，一旦weight可以影响memory里面的值，这个影响就会永远存在，每次都会有新的东西加进来，不会被直接覆盖掉，除非forget gate打算把memory cell的值忘掉；但RNN是直接覆盖，前面的影响就消失了。

#### Gated Recurrent Unit（GRU）

比LSTM更简单，gate的数量只有俩，即forget gate和input gate，这两者有一个联动：

* 当input gate打开时，forget gate关闭，forget掉menory里的值
* 当forget gate打开时，记住memory里的值，input gate关闭，不再进行输入

## Semi-supervised(半监督式学习)

前面说到的机器学习问题都是有监督的学习，今这进一步谈一谈半监督的学习。

在分类问题中，会有很多没有标签的数据，这些数据其实也可以参与到训练中，提高模型的精度。

### how to do

* 使用有标签的数据训练出模型之后，把没标签的数据丢进模型
* 根据模型得到的结果强制把数据进行分类。
* 因为分类问题中，往往是有一条清晰的分界线的，数据多了之后，这个boundary可能会改变，从而得到更准确的分类结果

### 进阶——Entropy-based regularization

直接强制分类的方式可能太武断了，这时就提出了这样一种该建筑$y^\mu=f^*_{\theta^*}(x^\mu)$.这其中$y^\mu$是一个概率分布。因为我们不知道没有被标签的数据属于哪个分类，很难知道强制分类的效果。但是分类问题有一个特点，是有明确的类型目标的，这个时候我们只需要判断分类的结果的离散程度，如果很集中，说明分类效果比较好。

那么就需要一种方式来量化这个离散程度——熵。很熟悉的函数了，公式之前也接触过，就不详细说了：
$$
E(y^u) = -\sum^5_{m=1}y^u_mln(y^u_m)
$$
至此，我们的目标其实已经很清晰了，“在labeled data上的分类要正确，在unlabeled data上的分类要集中”，那么对于损失函数我们就有了新的理解：

* labeled data，与正确的label越接近越好，用 cross entropy表示：$L = \sum_{x^r}C(y^r,\hat{y}^r)$
* unlabeled data,数据越集中越好，使用entropy：$L = \sum_{x^u}E(y^u)$
* 所以最后的损失函数就要把两者结合起来，然后用一个参数$\lambda$决定哪个更重要

$$
L(x)=\sum_{x^r}C(y^r,\hat{y}^r) + \lambda\sum_{x^u}E(y^u)
$$

可以看到，最后的形式和regularization很像，所以这也是entropy regularization名称的由来。

### Semi-supervised SVM

很无赖的方式，对所有没有标签的data枚举，然后对比不同的模型，期中区分度最大且分类错误最少的是最好的。

但是数据一多指数增长的数据量比较难以承受，大的数据量不可行

### Smoothness Assumption

基本精神：近朱者赤近墨者黑。

类似于强连通分量的概念，在考虑两个点的相似度的时候不是考虑域上的距离，而是在分块的时候看他和某个点是否属于同一块【有相连的路径】。

#### cluster and then label

把data分成几个cluster再拿去训练，但是这个cluster的过程一般没那么容易，因为这相当于是几乎分好类了。

就拿图像识别来说，直接用pixel的相似度来划分往往是不准确的，需要设计一个方式来提取出feature才能有比较好的效果。

#### Graph-based Approach

建图，比较简单的状态是建立网页链接/论文引用这样的关系，可以直接连线，但是有的时候需要自己寻找vertex之间的关系。具体的做法需要凭经验和直觉来做：

* 定义两个obeject之间的相似度 $s(x^i,x^j)$,这个相似度要基于feature计算，而不是pixel
* 依据相似度建图
  * k nearest neighbor
  * e-neighborhood
* 边长也可以给上具体的weight，体现相似度的比例关系
  * 建议用RBM function来确定相似度$s(x^i,x^j)=e^{-\gamma\parallel x^i-x^j\parallel ^2}$,计算两个向量的欧几里得距离加上参数后取做exponential
  * 加exponential的目的是让稍远一点的点的距离立马变大
  * 有效避免跨区域相连
  * 有一个很重要的点是数据要够多，不然可能点还没传递出去就断掉了

#### 定量使用smoothness

 $S=\frac{1}{2}\sum_{i,j}\omega_{i,j}(y^i-y^j)^2$

上述式子可以化简，如果把labeled和unlabeled的y组成一个（R+U）-dim的vector，smooth就可以改写为
$$
S=\frac{1}{2}\sum_{i,j}\omega_{i,j}(y^i-y^j)^2=y^TLy
$$
其中L是一个$(R+U)\times(R+U)$的matrix，成伪 **Graph Laplacian** 定义为L=D-W

* W:把data point两两之间的weight建成matrix
* D：把W每一行的值加起来放在对应的diagonal上

所以这个时候我们又可以修改损失函数了
$$
L=\sum_{x^\gamma}C(y^\gamma,\hat{y}^\gamma)+\lambda S
$$
从形式上可以看出，$\lambda S$实际上也是一个regularization term

具体训练的时候不要局限于output做smooth，其实中间任意一个hidden layer都可以加上smooth的限制。

## Word Embedding

分类问题其实是一个多对一的问题，但是有的时候，比如词性标注的时候，我们要解决的问题是一个多对多的问题。而且有的时候，在单纯的分类问题里，可能一万个data会有一万个种类，但是如果做word embedding，可能只需要五十个维度就可以完整描述这些词了。这种问题的输入是一个word，输出是一个vector。

这一章主要描述两种生成词向量的手段

### Count based

基于计数的统计方法。如果两个单词$\omega_i,\omega_j$常常一起出现，我们就可以认为他们的vector是非常接近的。

用$N_{i,j}$表示$\omega_i,\omega_j$在同一个document中出现的次数，我们希望找到对应的$V(\omega_i)$和$V(\omega_j)$,其做inner product的值和这个次数越接近越好。

代表方法：[Glove vector](https://nlp.stanford.edu/projects/glove/)

### Prediction-based

基于预测的统计方法，通过上下文预测中心词或通过中心词预测上下文

相当于network的每一层layer都是输入一个vector（对应的词是1其他都是0）输出一个n维（n个词）的vector，表示这个词后面出现某个词的概率。

#### share weight

但从一个词来预测可能不太准确，我们的输入可以是两个vector分别对应$w_{i-1},w_{i-2}$。

#### How to do

如果我们设置$x_{i−1},x_{i−2}$的长度都是$\mid V \mid $,$z$的长度是$\mid Z \mid $，那么
$$
z=W_1x_{i-2}+W_2x_{i-1}
$$
其中$W_1=W_2=W$,那么$z=W(x_{i-2}+x_{i-1})$也就得到了word vector $V(w)$

![image-20200723170349618](/images/posts/ML-notes/image-20200723170349618.png)

实际的训练中要保证$W_1=W_2$，需要做到以下两点：

* 初始化为相同的值
* 每次更新的值一样

$$
w_i\leftarrow w_i-\eta\frac{\partial C}{\partial w_i}-\eta\frac{\partial C}{\partial w_j}\\
w_j\leftarrow w_j-\eta\frac{\partial C}{\partial w_j}-\eta\frac{\partial C}{\partial w_i}\\
$$

#### Training

输出的error function依然是使用cross entropy

#### Various Architectures

两个模型

* CBOW：根据上下文的词汇$w_{i−1},w_{i+1}$来预测中心词$w_i$
* Skip-gram：根据中心词$w_i$来预测上下文$w_{i−1},w_{i+1}$

![image-20200723173416934](/images/posts/ML-notes/image-20200723173416934.png)

## Explainable ML

机器学习不能只告诉我们答案，还要告诉我们判据。

否则可能**只是恰巧某个情况精度很高，实际上机器什么都没学到**

Interpretable 和powerful同等重要

### Local Explanation

#### Basic Idea 

对于输入的x，把它分成多个components【由一个像素，或者一小块组成】。

我们就可以据此remove或modify一个component的值，看看decision会有什么变化。

或者对某个关键的pixel加上$\triangle x$ 我们就可以使用$\frac{\triangle y}{\triangle x}$来表示这个小小的扰动对y的影响。再通过$\frac{\partial y_k}{\partial x_n}$来计算表示$y_k$对$x_n$的偏微分，最后取绝对值表示一个pixel对y的影响大小。

#### Limitation of Gradient based Approaches

![image-20200723182303917](/images/posts/ML-notes/image-20200723182303917.png)

#### Attack Interpretation

![image-20200723182323958](/images/posts/ML-notes/image-20200723182323958.png)

### Global Explanation

通过解释整个图片来实现

#### Activation Minimization（review）

先review一下activation minimization，现在我们的目标是找到一个$x^∗$，使得输出的值yiyi最大

我们可以加入一些噪声，加上噪声后人并不能识别出来，但机器可以识别出来，看出来下图中的噪声是0 1 2 3 4 5 6 7 8

![image-20200723195255708](/images/posts/ML-notes/image-20200723195255708.png)

之前我们的目标是找到一个image，使得输出的y达到最大值；现在我们的目标不仅是找到x使输出y达到最大值，还需要把image变得更像是一个digit，不像左边那个图，几乎全部的像素点都是白色，右边的图只有和输出的digit相关的pixel才是白色

这里我们通过加入了一个新的限制R(x)R(x)来实现，可以表示图像和digit的相似度.

![image-20200723195329500](/images/posts/ML-notes/image-20200723195329500.png)

#### Constraint from Generator

用generator画出image $x$，再扔到分类器里看是不是对应的label

### Using a model to explain another

用一个interpretable的模型【即标准答案】和现在的模型输出比较。

![image-20200723205930669](/images/posts/ML-notes/image-20200723205930669.png)

实际上并不能使用linear model来模拟整个neural network，但可以用来模拟其中一个local region

#### Local Interpretable Model-Agnostic Explanations (LIME)

##### General

用一维的数据举例：

* 首先给出要explain的point，代入black box里面
* 在第三个蓝色point（我们想要模拟的区域）周围sample附近的point，nearby的区域不同，结果也会不同
* 使用linear model来模拟neural network在这个区域的行为
* 得知了该区域的linear model之后，我们就可以知道在该区域x和y的关系，即x越大，y越小，也就interpret了原来的neural network在这部分区域的行为

![image-20200723210451263](/images/posts/ML-notes/image-20200723210451263.png)

那么到底什么算是nearby呢？**用不同的方法进行sample，结果不太一样。**对于下图中的region，可以看到离第三个蓝色point的距离很远，取得的效果就非常不好了

![image-20200723210529489](/images/posts/ML-notes/image-20200723210529489.png)

##### LIME-Image

说完了general的情况，接下来是对image的应用。

![image-20200723210709800](/images/posts/ML-notes/image-20200723210709800.png)

* 首先需要一张需要解释的image；为什么这张图片可以被classify为树蛙？
* sample at the nearby：首先把image分成多个segment，再随机去掉图中的一些segment，就得到了不同的新图片，这些新的图片就是sample的结果；再把这些新生成的图片输入black box，得到新图片是frog的可能性
* fit with linear model：即找到一个linear model来fit第3步输出的结果；先extract生成的新图片的特征，再把这些特征输入linear model

将image转化为一个vector的方法：

将image中的每个segment使用$x_i$来表示，其中$i=1,…,m,…,M$ , $M$为segment的数量；$x_i$为1，表示当前segment被deleted，如果为0，表示exist

![image-20200724110742734](/images/posts/ML-notes/image-20200724110742734.png)

* Interpret the model：对于学习出来的linear model，我们就可以对其进行interpret；首先需要将$xi$和y的关系用一个公式表示出来，即

$$
y=w_1x_1+..+w_mx_m+...+w_Mx_M
$$

这个公式中的$w_m$有三种情况：

* $w_m\approx 0$，segment $x_m$被认为对分类为frog没有影响；
* $w_m>0$， $x_m$对图片分类为frog是有正面的影响的；
* $w_m<0$， 看到这个segment，反而会让机器认为图片不是frog

#### Decision Tree

如果我们用不限制深度的decision tree，那么我们就可以使用decision tree来模拟black box（neural network），使两者的输出相近

但decision tree的深度不可能是没有限制的。这里我们设neural network的参数为$\theta$，decision tree的参数为$T_\theta$，使用$O(T_θ)$来表示$T_θ$的复杂度，复杂度可以用$T_θ$的深度来表示，也可以用neural的个数来表示；现在我们的目标**不仅是使两者输出相近，还需要使$O(T_θ)$的值最小化**

##### 如何实现$T_\theta$最小化？

如下图所示，我们首先训练一个network，这个network可以很容易地被decision tree解释，使decision tree的复杂度没有那么高；这里我们加入了一个正则项$λO(T_θ)$，在训练network的同时，不仅要最小化loss function，还需要使$O(T_θ)$的值尽量小，这时需要找到的network参数为$\theta^∗$
$$
\theta^∗=arg min L(\theta)+\lambda O(T_\theta)
$$
