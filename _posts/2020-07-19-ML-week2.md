---
layout: post
title: 机器学习-Week2笔记
date: 2020-07-19
tag: ML-notes
---

## Logistic Regression 逻辑回归

从上周的最后一节课，我们可以看到推导出来这个分类的model其实是一个由$\omega$和$b$决定的model，我们称之为**Logistic Regression（逻辑回归）**

### Logistic Regression的具体过程

#### Step1：Function set

<img src="/images/posts/ML-notes/image-20200713104741294.png" alt="image-20200713104741294" style="zoom: 67%;" />

#### Step2： Goodness of a Function

目标：现在我们有N笔Training data，每一笔data都要标注它是属于哪一个class

假设这些Training data是从我们定义的posterior Probability中产生的(后置概率，某种意义上就是概率密度函数)，而w和b就决定了这个posterior Probability，那我们就可以去计算某一组w和b去产生这N笔Training data的概率，这里使用 **极大似然估计** 的思想

![img](/images/posts/ML-notes/likelihood.png)

首先进行取对数这种常规的数学化简，

![image-20200713105846491](/images/posts/ML-notes/image-20200713105846491.png)

然后为了统一表达式，我们可以对训练集打标签，归为class1则$\hat{y}=1$反之$\hat{y}=0$， 于是课可以把上式写成一个统一的格式。

$$-lnL(\omega,b)=\sum-[\hat{y}^nlnf_{\omega,b}(x^n)+(1-\hat{y}^n)ln(1-f_{\omega,b}(x^n))]$$

对于分类问题这样一个可以看作两点分布的问题来说，这个式子括号里面其实是一个cross entropy（交叉熵）

#### Step3：Find the best function

同样使用gradient descent的方法找Loss Function最小值，这里Sigmoid function是一个常用的微分，可以记忆一下：$\sigma(z)(1-\sigma(z))$，图像如下：

![img](/images/posts/ML-notes/sigmoid.png)

接着计算$-lnL(\omega,b)=\sum-[\hat{y}^nlnf_{\omega,b}(x^n)+(1-\hat{y}^n)ln(1-f_{\omega,b}(x^n))]$对$\omega_{i}$的偏微分，过程不赘述了，最后的结果比较简洁：$-(\hat{y}^n-f_{\omega,b}(x^n))x^n_i$。所以这里我们就可以找到每次需要update的值：$\eta\sum_n-(\hat{y}^n-f_{\omega,b}(x^n))x^n_i$

### Logistic Regression V.s. Linear Regression

* step1：function的output不同，前者的范围介于0~1，而后者没有范围限制
* step2：前者可以看作样本点和实际点在两点分布下的交叉熵的总和，后者就是样本点和实际点的差距平方和
* step3：利用相类似的方式进行更新

![image-20200713162611002](/images/posts/ML-notes/image-20200713162611002.png)

#### 为什么Logistic Regression的loss function不能用square error来描述？

课堂上试验了一下，可以很容易想到对于一个二分类问题，作方差和的时候会出现在分类很接近或者很遥远的时候，根据公式都会得到微分变成0的情况，有一个很直观的图片来展示这种现象

![image-20200713163056296](/images/posts/ML-notes/image-20200713163056296.png)

所以在离target很近或很远的时候微分的值都是很小的，这就会导致这个学习的速度很慢，使用cross entropy可以让学习的过程更加顺利。

### Discriminative v.s. Generative

Logistic Regression的方法，我们把它称之为discriminative的方法；而我们用Gaussian来描述posterior Probability这件事，我们称之为Generative的方法。

* 这两种方式，其实使用的model是一样的，都是$P(C_1\mid x)=\sigma(\omega\cdot x+b)$ ，
* 但是这两种方式得到的参数是不一样的，为什么？
  * 后者成立的条件其实是和前者不一样的，后者对Probability distribution是**有实质性的假设**的，这里的假设约束是 **这个分布符合高斯分布**，甚至还假设了在相互独立的前提下是否可以是naive bayes(朴素贝叶斯)
* 两种方法的准确度也是不一样的
  * 在课堂的例子中Discriminative是显著好于Generative的，因为后者对这个粉不做了一个并不应该存在的假设，就使得设定的参数脱离了实际数据本身。
  * 大部分情况下过多的假设是一个不好的事情，因为这相当于预设了数据一些并没有的特性，但是有的时候后者的学习能力有可能会超过前者——在**data数量不足**或**data的label存在问题**的时候，有一些合理的假设可以更好地拟合出需要的模型

### Multi-class Classification

#### softmax 强化最大值

我们把$z_1,z_2,z_3$丢进一个**softmax**的function，softmax做的事情是这样三步：

* 取exponential，得到$e^{z_1},e^{z_2},e^{z_3}$
* 把三个exponential累计求和，得到total sum=$\sum^3_{j=1}e^{z_j}$
* 归一化：$y_1=\frac{e^{z_1}}{\sum^3_{j=1}e^{z_j}},y_2=\frac{e^{z_2}}{\sum^3_{j=1}e^{z_j}},y_3=\frac{e^{z_4}}{\sum^3_{j=1}e^{z_j}}$ 

做完这个步骤之后output的y值就一定是介于0~1之间的，这个output就是拿来当z的posterior probability的。

用Gaussian distribution(共用covariance)和这个softmax的function是等价的。而从信息论可以推导出softmax function，[Maximum entropy](https://en.wikipedia.org/wiki/Maximum_entropy)本质内容和Logistic Regression是一样的。

#### classification的过程

同样计算取对数计算三个和的交叉熵，用极大似然估计法得到表达式求极值。

### Logistic Regression的限制

一个经典的图：数据不是很好的时候没法在平面上把两个类分开。

![image-20200713191348431](/images/posts/ML-notes/image-20200713191348431.png)

#### Feature Transformation

对特性的空间做一个变换，使其可以明显地被区分开来

然后这个变换我们希望机器自己产生：让logistic Regression cascade（级联）起来

![image-20200713192217421](/images/posts/ML-notes/image-20200713192217421.png)

看了两遍视频，感觉意思大概是用n个 Logistic Regression的函数，对每个函数输入n个输入，就可以得到n个n维的输出。

通过上面的例子，我们发现，多个Logistic Regression连接起来会产生powerful的效果，我们把每一个Logistic Regression叫做一个**neuron(神经元)**，把这些Logistic Regression串起来所形成的network，就叫做**Neural Network**，就是类神经网路，这个东西就是**Deep Learning！**

所以现在进入了Deep Learning的范畴！进入正片！

## Deep Learning

讲故事略过，实际上deep learning也是三个步骤，第一个步骤就是构建神经网络的模型

### Neural Network

概念上一节说过：多个Logistic Regression连接起来，每一个Logistic Regression叫做一个**neuron(神经元)**，一个整体叫做**Neural Network**

用不同的方法连接neuron就可以得到不同的structure， neural network里的每一个Logistic Regression都有自己的weight和bias，这些weight和bias集合起来，就是这个network的parameter，我们用$\theta$来描述

#### Fully Connect Feedforward Network全连接前馈网络

![image-20200714092213920](/images/posts/ML-notes/image-20200714092213920.png)



每一排表示一个layer，每个layer里面的每一个球都代表一个neuron

* input的地方叫input layer，output的地方叫output layer
* 中间的叫hidden layer

每一个neuron里面的function再deep learning中被称为 activation function（激励函数）

有很多层layer的neural network，被称为**DNN（Deep Neural Network）**

#### Matrix Operation

network的运作过程，我们通常会用Matrix Operation来表示。

注意$W^i$的matrix，每一行对应的是一个neuron的weight，行数就是neuron的个数，而input x，bias b和output y都是一个列向量，行数就是feature的个数(也是neuron的个数，neuron的本质就是把feature transform到另一个space)。

写成矩阵运算的好处：GPU对矩阵运算的加速效果很好。

#### 每一层layer的实际意义

* hidden layers ：其实是一个feature extractor，最后提取出来的就是一组新的feature
* output layer：其实最后一层才是真正的分类器，拿着经过前面神经网络训练出来的数据进行分类，所以一般会在最后一层加上一个softmax

### Example Application

一个手写识别的应用举例

输入是一个16x16的图片，输出是0-9这十个数字。那么输入其实就是一个256的vector，而输出则是一个10维的vector。那现在要做的事情就是对中间的network structure进行design，不同的design往往对最后的结果有很大的影响。

结构确定好之后就和前面的学习方式一样，最后依然是Gradient Descent求Loss Function的最小值，得到所有神经元的$\omega，b$。这里的参数多起来之后，手算微分变得不太可能，这里我们有pytorch等工具帮助我们做这些复杂的计算。

### Why Deep？

既然我们最后要找的就是一个function，其实就是控制参数而已，那么deep在找参数的这个锅成有什么特殊的意义么？

Deep本身是一种抽取feature的过程，至于是否使用这种方式来抽取feature，取决于你觉得这种方式是否有助于你更轻松地抽取出feature。

## Backpropagation 反向传播

Backpropagation(反向传播)，就是告诉我们用gradient descent来train一个neural network的时候该怎么做，它只是求微分的一种方法，一种更有效率的方法，而不是一种新的算法。【这个计算现成的toolkit一般能帮我们完成，但我们还是要学原理~】

### Chain Rule

复习一下求微分的链式法则：

* case1: $\frac{dz}{dx}=\frac{dz}{dy} \cdot \frac{dy}{dx}$
* case2: $\frac{dz}{ds}=\frac{dz}{dx} \cdot \frac{dx}{ds}+\frac{dz}{dy} \cdot \frac{dy}{ds}$

按照chain rule，$\frac{dL}{d\omega}=\frac{dz}{d\omega} \cdot \frac{dL}{dz}$

前面这一项【Forward pass】是比较简单的，而后面这一项【Backward pass】不好计算。

* Forward pass：w前面连接的input是什么，那微分后的$\frac{dz}{d\omega}$值就是什么
* Backward pass：用类似递归的思想，每一个神经元都是可以根据后一个神经元的z'算出来，相当于一直走到到末尾再递归回来，也可以看作是一个反向的神经网络。
  * 经典例图：<img src="/images/posts/ML-notes/image-20200714191708224.png" alt="image-20200714191708224" style="zoom: 50%;" /><img src="/images/posts/ML-notes/image-20200714191742352.png" alt="image-20200714191742352" style="zoom:50%;" />
  * 所以实际写程序运算的过程中其实不需要反复计算后面的值，只需要建一个反向的神经网络，只需要计算一次就可以反复利用结果。

## Convolutional Neural Network（CNN）

### CNN V.s. DNN

其实这是一个不太需要解释的过程，CNN其实是对DNN的一种简化。事实上，在做神经网络的时候，我们希望每一层做的事情其实都是一个分类，对图像的一些特征进行提取。在图像识别的问题中，我们需要根据自己的知识和对图像处理的理解，一开始就把某些实际上用不到的参数给过滤掉，我们一开始就想一些办法，不要用fully connected network，而是用比较少的参数，来做图像处理这件事情，

### Three Property for CNN theory base

#### Some patterns are much smaller than the whole image

对一些特征的提取不需要看整张图片，只需要看一小部分，举例：找鸟嘴

#### The same patterns appear in different regions

对于同一个特征，可能出现在图片的不同位置，但是只需要用同一组参数来识别，举例：不同位置的鸟嘴

#### Subsampling the pixels will not change the object

假如你把它奇数行、偶数列的pixel拿掉，image就可以变成原来的十分之一大小，而且并不会影响人对这张image的理解，对机器也是一样的，因此可以用这个概念把图片缩小，自然参数就消了不少了。

### The whole CNN structure

首先，input一张image以后，它会先通过Convolution的layer，接下来做Max Pooling这件事，然后再去做Convolution，再做Maxi Pooling...，这个process可以反复进行多次(重复次数需要事先决定)，这就是network的架构，就好像network有几层一样，你要做几次convolution，做几次Max Pooling，在定这个network的架构时就要事先决定好。

当你做完先前决定的convolution和max pooling的次数后，你要做的事情是Flatten，做完flatten以后，你就把Flatten output丢到一般的Fully connected network里面去，最终得到影像辨识的结果。

![image-20200715094709868](/images/posts/ML-notes/image-20200715094709868.png)

#### Convolution

考虑property1/2的具体操作就不赘述了。使用filter做内积的过程其实就是把特征放大的过程，符合规则的特征在这个时候会得到卷积的最大值。

**Feature Map：**在坐convolution的layer里面，会有很多的filter，不一样的filter会有不同的参数，但是这个卷积的过程都是一样的，所以会得到一堆规格相同的matrix的集合，这些matrix合起来，就叫做Feature Map。

**scale转换：**CNN对不同scale的相同pattern是没法很好处理的，比如说识别鸟嘴，有不同size的鸟嘴需要识别，不能直接通过CNN来自动识别，这就要在CNN前面input的时候加一个network，这个network吧image里面的一些位置做旋转缩放，再丢到CNN里面，performance就会比较好。

#### Colorful image

彩色的图片实际上是由rgb组成，所以每一张图片都是一个高为3的立方体，同样的，filter也是高为3的立方体，于是在做内积的时候是把filter的每一层分别跟image的3层做内积，每一个值也和image一层里面的每个值做内积，得到的也是一个3层的output。

### Convolution V.s. Fullyconnected

看起来filter和原来的neural没什么关系，但是实际上这就是一种神经的连接，从课堂上的图可以看出来：把一个矩阵拉成一个直线之后，期中的九个参数连进了neural，就是所谓的选择部分参数进行深度学习。

减少参数的两个方式：

* 一次学习只用到了和filter匹配的部分pixel
* 移动一个步长的时候可以明显看到有一些数值是被共用了的，就不放图了【一个值会用在多个neuron里】

CNN的本质就是减少参数的过程。

具体的内部实现都用工具来做，如果要自己写的话其实和前面的事一样的，只是一些值是代入0去计算。

### Max Pooling

在四个格子里找到值最大的，达到缩小图片的目的，也是相当于强化了特征值。

### Convolution +Max Pooling

每做完一次这样的操作之后就是filter有几个就有几层matrix，这个层也可称作channel。

那么是不是每一次做完之后channel都会平方呢？不是的，每一次做完之后同一个channel的结果会叠加。

### Flatten

做完前面的步骤之后把feature map拉直，然后丢进后面fully connected Feedforward network的部分。

这节课后面的部分就是举了一些具体的例子讲解CNN的步骤，比如alpha Go，语音识别等等，科普为主。

## Tips of Deep Learning

这一讲主要讲一些操作上的细节，如何提高准确率

### Recipe of Deep learning

deep learning的三个步骤：

* define the function set(network structure)
* goodness of function(loss function -- cross entropy)
* pick the best function(gradient descent -- opimization)

![image-20200715230803897](/images/posts/ML-notes/image-20200715230803897.png)



#### Good Results on Training Data？

有一个误区：deep learning 参数那么多，会不会很容易overfitting？实际上不会，在这个过程中其实对training set的结果往往都不太好，不像一些临近点问题或决策树问题，很容易就在traning set上100%。所以这一步是非常需要提高在training set的正确率的。

#### Good Results on Testing Data？

这个步骤就是解决overfitting的步骤了，其实在很多机器学习的例子上，一般都在花大量时间解决这个问题，但是深度学习的话第一个问题反而也是比较棘手的事情。

#### Do not always blame overfitting

![image-20200716092926073](/images/posts/ML-notes/image-20200716092926073.png)

以这个图像为例，第一眼看过去会觉得56层的情况下比20层error大，是不是overfitting了。但是这是一个误区，因为我们没有去观测training data的值，只有training data的时候56层的结果更好，才能说这是一个overfitting。

除了 overfitting， 还有很多问题会导致更大的错误率，比如我们有local minimum的问题，有saddle point的问题，有plateau的问题。

有一种说法是这是underfitting，但是李老师不认同，underfitting应该是参数不够导致的模型不准确，而这个56层明显参数更多，这应该是没train好，不过这也只是一个名词的认为定义，不关键。

说完了哪些部分可能导致不好的performance，后面的内容则是描述如何优化他们。

### Training data 部分的优化

#### Vanishing Gradient Problem

Sigmoid function是上世纪八十年代较为常用的训练用activation function，但是在进行深度学习的时候，你会发现层数深了以后准确率就会变得很低。这个问题就是Vanishing Gradient（梯度消失）引起的，当你把network叠得很深的时候，在靠近input的地方，这些参数的gradient(即对最后loss function的微分)是比较小的；而在比较靠近output的地方，它对loss的微分值会是比较大的。所以在刚开始其实才训练了没多久的时候，机器就会在速率几乎为0的情况下认为已经到达了gobal minima，从而导致停止学习，得到一个没有充分training的结果。

换一种理解方式，我们回看backpropagation的部分（就不重复写在这里了）就会发现input那边的weight对loss的影响远小于靠近output的weight，所以在入口的时候梯度几乎就消失了。

#### train RBM

先把第一个layer train好，再去train第二个....

#### new activate function

##### **Rectified Linear Unit（ReLU）整流线性单元函数**

![image-20200716101411135](/images/posts/ML-notes/image-20200716101411135.png)

使用ReLU的理由：

* 运算简单，快速
* 结合了生物上的观察（Pengel 的paper）
* 无穷多bias不同的sigmoid function叠加的结果会变成ReLU
* 可以处理上面提到的梯度消失问题

虽然每一层是linear的，但是合在一起就是non-linear的

**一些细节需要处理**

* 如何微分：>0时微分就是1，<0微分就是0，=0直接拿掉不要
* <0如何update：<0的时候给一个小参数，让有一点点值（Leaky ReLU），更进阶的方式是【parametric ReLU】，给一个通过training data学习出来的参数。

##### **Maxout——更进阶的activation function**

基本想法：通过network自动学出activation function 。把k个element分为一个group，使用max取出函数的最大值，可以断到一个分段的线性凸函数。用这样的方法可以学习出多种常用的activation function。

如果担心无法微分，完全可以在实际的应用中根据数据把max函数换成一个具体的函数，再对转化后的函数进行微分。

不用担心会有参数train不到，实际上应用的时候会有很多笔data，最后每一个参数都会被train到。

Max pooling遇到难以微分的情况可以用和MAx类似的方式解决。

#### Adaptive Learning Rate

Adagrad的问题：事实上不是所有的图像都像上次的例子那样简单，不会说一直保持着gradient比较大或者比较小

##### **RMSProp**

相当于Adagrad的进阶版，更加dynamic地调整learning rate

*tips：这个方法不是哪篇paper提出来的，而是一个course里面讲到的，cite还要去cite Hinton的课程链接*

**How to do：**
$$
\omega^{t+1}=\omega^t-\frac{\eta}{\sigma^t}g^t\\
\sigma^t = \sqrt{\alpha(\sigma^{t-1})^2+(1-\alpha)(g^{t})^2}
$$
从整体上来说，这个方法也是综合考虑了整个过程的gradient信息，但是这是一个更有权重的考虑，比如$\alpha$的值小一些，新的gradient的info就更重要一些。

##### Momentum

担心local minima？

Yann LeCun 在07年就提出了：local minma必须是所有的参数都是在山谷的位置才有可能，但是做deep learning 的时候参数很多，所以反而出现local minma的概率越低。

但是你说你还是担心，所以Momentum这个方法就出现了。

原理就是现实生活中的momentum：你只要把一个惯性加到gradient descent里面，就会比较容易滚出local minma

**How to do：**

课上说的有点绕，实际上好像就是加一个参数$\lambda v^{i-1}$，通过参数$\lambda$来决定上一步的前进量对这一步的影响，**注意：这是一个矢量加和**

##### Adam

本质上就是**RMSProp+Momentum**

* 初始化$m_0=0,v_0=0,t=0$

* 计算gradient $g_t=\triangledown_\theta f_t(\theta_{t-1})$

* 再根据过去要走的方向$m_{t-1}$和gradient $g_t$，算出要走的方向$m_t$：$m_t=\beta_1m_{t-1}+(1-\beta_1)g_t$

* 再算分母上的 $v_t=\beta_2v_{t-1}+(1-\beta_2)g^2_t$

* 比较新颖的一步：bias correction

  * $\hat{m_t}=\frac{m_t}{1-\beta_1^t}$
  * $\hat{v_t}=\frac{v_t}{1-\beta_2^t}$

* 最后update的操作

  * $$
    \theta_t=\theta_{t-1}-\frac{\alpha\cdot\hat{m_t}}{\sqrt{\hat{v_t}}+\epsilon}
    $$

### Testing data 部分的优化

这一部分的话主要分成三个板块： **Early Stopping，Regularization，Dropout**

前面两个方法是比较通用的方法，最后一个是deep learning的特色做法

#### Early Stopping

防止过拟合，在Testing set【Validation set】error达到最小的时候及时停下

#### Regularization

##### L2正则 

上面讲过一次，具体的做法不详细说了，原理就是每次微分会让参数变小，又称为Weight Decay

##### L1正则

把L2里的平方变成绝对值【所谓的一次项】，根据绝对值函数的特征，大于0的时候微分就是1，小于零就是-1，在0的时候可以随意给一个值比如0，所以每次update也是让参数逐渐接近0

##### L1 V. s. L2

L1每次减去固定值，L2乘上一个小于1的固定值。所以L2减小的速度和数的大小关系比较大，而L1相对固定。这就导致了L1train出来的参数往往更加sparse，比如CNN就希望有比较spare（稀疏）的参数，用L1就更合适一些。

#### Dropout

##### How to do

每一次update都通过sampling丢掉一些neuron，丢完了之后才开始train这个细长的network。因为参数少了，可以看到会在training set上结果其实会更差，但是testing data上会变好。test的时候要注意两件事：

* testing的时候不做dropout，所有的neuron都要被用到。
* 加入traning的时候dropout的rate是p%，最后所有的weight都要乘上（1-p%）才能被当作testing的weight使用。

##### Why Dropout

有很多解释，比较令人信服的一种是：dropout是一种终极的ensemble的方法。

这里没有很弄懂，感觉老师的意思就是分别训练不同的neuron可以在bias和variance中寻找平衡。相当于训练了好几个network然后分别把input放进去得到的output平均一下【实际运作中没有多个network而是使用一个完整的然后乘以一个系数】就准确度提升了。具体是怎么得到这个结论的我还没能理解...

不过要注意，**只有linear的network才符合ensemble**，不过不符合的时候（指non-linear）最后的结果却也还是work，比较神奇。

当然，可以看到的是linear的network用上这个方法会得到比较好的performance，而ReLU和Maxout就是这样的两个线性的方法，经常配合Dropout使用。

## Why Deep

这节课主要探讨Deep的一些内容，重点比较了Shallow 和 Deep的区别。

### Shallow V.s. Deep

#### Deep is Better?

有的观点认为Deep效果好的原因只是参数多，那么一层很多neuron的shallow neural network是不是可以达到同样的效果呢？

答案是不可以，而且Deep好得很显著

### 如何理解Deep更好这件事情？

从一个直观的角度来说，Deep像是把一个目的分成多个步骤，每个步骤只处理一些简单的分类，这个准确率就非常高，但Shallow如果只有一层，那这一层要处理所有的分类情况，难度就很大，所以说Deep是在做modularization这件事，所以训练出准确的模型所需要的数据量就更小一些。

### 语音识别中的应用

语音的特征有phoneme和state两个特征，如果不用deep往往是对这两个特征做independent的model【HMM-GMM】，而这样做的效率不高。DNN的话会先用比较lower的layer去观测人在用什么方式发这个生意，然后再根据layer出来的结果进行分类，所以这个layer可以说是人类发音方式的一个detector，最后的分类器都是share了前面的参数，就提升了效率

### Analogy

用剪窗花和电路比喻了一下Deep，不太重要就不记录了

### End-to-end Learning

只给model的input和output，不告诉中间的函数怎么分工，让它自己学会自己在每一站要做什么事情，即DNN中的每一层要做什么事情

往年的语音处理中间的很多function都是以前的科学家努力弄出来的，但是现在用DNN的话后面好几个function都不用自己去推测是怎样的，而是叠一个很深很深的neural network

### Complex Task

举了几个例子说明多层次的network能够把很相似的东西分出来，或者说把很不相似的东西提取到相同的特点，在复杂的任务上表现更好一些。


